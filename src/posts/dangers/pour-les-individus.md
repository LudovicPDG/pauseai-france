---
title: Dangers pour les individus
description: L'intégration de l'IA dans la vie quotidienne présente des dangers pour la vie privée, la sécurité et le bien-être des individus, nécessitant des régulations, une éducation du public et des systèmes d'IA sécurisés pour les atténuer.
---

L'intégration de l'IA dans la vie quotidienne pose des dangers significatifs pour les individus, touchant à leur vie privée, leur sécurité et leur bien-être. Ces dangers incluent la violation de la confidentialité, la désinformation et la manipulation, avec pour conséquence des dommages émotionnels ou physiques graves. Pour atténuer ces dangers, il est crucial de mettre en place des cadres réglementaires robustes et des pratiques de sensibilisation et d'éducation auprès du public, ainsi que des gardes-fous intégrés aux systèmes d’IA.

## Violation de la vie privée et de la confidentialité

L’intégration de systèmes d’IA dans des objets pervasifs dans notre société tels que des ordinateurs ou caméras de surveillance, à des fins d’analyse locale ou de collecte de données centralise les données privées ce qui rend les fuites plus graves. De plus, les données d’utilisation des systèmes d’IA sont généralement collectées par les développeurs pour améliorer leurs produits et se retrouvent d’une certaine manière dans les IA futures.

Pour ne pas être victime, ne partagez pas vos données personnelles, vos travaux ou des données confidentielles avec des systèmes d’IA. Cependant, cela restreint fortement l’usage qu’on peut en faire au quotidien.

Ce danger peut être mitigé en régulant l’usage et la protection des données par les fournisseurs d’IA. Des techniques de marquage au filigrane ou d’empoisonnement pourraient aider à éviter ce problème.

## Deepfakes

Les IA génératives, notamment de voix et d’images, peuvent être utilisées pour reproduire l’apparence et la voix de quelqu’un de précis à partir de quelques données récoltées en ligne.

Au-delà des inquiétudes éthiques, les deepfakes peuvent contribuer à des arnaques et à la désinformation, personnalisée ou généralisée. Les outils de deepfakes réduisent la barrière technique et psychologique à la falsification de contenu en ligne. N’est pas vrai tout ce que qu’on lit sur Internet, et désormais il est difficile de faire confiance même à des images ou des enregistrements audio.

Pour ne pas être victime de deepfake, de façon directe ou pervasive, tenez-vous au courant de ce qui peut être falsifié et assainissez votre consommation de contenu en ligne. Cela est malheureusement difficile à appliquer à l’échelle de la société.

Ce danger peut être mitigé par des régulations gouvernementales, et pour l’instant, il est encore possible de distinguer les deepfakes d’images ou de sons réels avec un peu d’entraînement.

Une réforme radicale de nos systèmes d’information sera nécessaire pour éviter complètement ce danger, mais le sujet est fortement débattu.

## Tromperie stratégique

Un système d’IA pourrait recourir à la tromperie pour atteindre ses fins, qu’il ait appris ce comportement par imitation/généralisation de mensonges humains, ou qu’il s’agisse d’une capacité instrumentale convergente.

Un tel système pourrait résister activement aux tentatives de supervision, de contrôle et de correction par ses développeurs et causer des dommages économiques, émotionnels ou physiques aux humains qu’il manipule. Si ses objectifs sont néfastes à la société, il pourrait aussi causer des dégâts par ses efforts pour atteindre ses objectifs.

Les techniques actuelles d’évaluation sont incapables de déterminer si les systèmes actuels d’IA sont capables de tromperie stratégique et s’ils en font preuve en pratique.

A moins que vous ne travailliez dans l’IA, vos actions les plus impactantes sur le sujet seront des actes citoyens.

Ce danger peut être mitigé par un contrôle à l’entraînement et au déploiement des IA de pointe. Il ne pourra être évité qu’en inventant de meilleures techniques d’alignement.
